{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 22:29:06,699 - INFO - \n",
      "Processing time slot: 108\n",
      "C:\\Users\\mamun_pc\\AppData\\Local\\Temp\\ipykernel_27788\\3987405872.py:584: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  total_path_df = pd.concat([total_path_df, path_df], ignore_index=True)\n",
      "2025-04-09 22:39:12,756 - INFO - Completed processing time slot 108\n",
      "2025-04-09 22:39:12,758 - INFO - All visualizations completed successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional, Union, Any\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class VisualizationConfig:\n",
    "    \"\"\"Configuration for visualization parameters\"\"\"\n",
    "    output_dir: str\n",
    "    data_files: List[str]\n",
    "    day_type: str\n",
    "    frequent_path: str\n",
    "    time_slots: List[int]\n",
    "    support_weight: float = 0.5\n",
    "    utilization_weight: float = 0.5\n",
    "    path_lengths_to_analyze: List[int] = None\n",
    "    k_critical_path: int =20\n",
    "    has_critical_path:bool = False\n",
    "    top_k: int = 10\n",
    "    text_size:int = 12\n",
    "    fig_size: Tuple[int, int] = (15, 10)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.path_lengths_to_analyze is None:\n",
    "            self.path_lengths_to_analyze = [2, 3, 4, 5]\n",
    "        assert np.isclose(self.support_weight + self.utilization_weight, 1.0), \"Weights must sum to 1\"\n",
    "\n",
    "class PathAnalyzer:\n",
    "    \"\"\"Handles path analysis and critical route calculations\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_path_length(items: Union[str, List, Any]) -> int:\n",
    "        \"\"\"Calculate path length from items\"\"\"\n",
    "        if isinstance(items, str):\n",
    "            try:\n",
    "                items = eval(items)\n",
    "            except:\n",
    "                return 1\n",
    "        return len(items) if isinstance(items, list) else 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_path_utilization(road_ids: Union[str, List], road_utilization: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate average utilization for a path\"\"\"\n",
    "        if isinstance(road_ids, str):\n",
    "            try:\n",
    "                road_ids = eval(road_ids)\n",
    "            except:\n",
    "                road_ids = [road_ids]\n",
    "        elif not isinstance(road_ids, list):\n",
    "            road_ids = [road_ids]\n",
    "            \n",
    "        path_utils = road_utilization[road_utilization['road_id'].isin(road_ids)]['utilization']\n",
    "        return path_utils.mean() if not path_utils.empty else 0.0\n",
    "    \n",
    "    def calculate_critical_routes(\n",
    "        self,\n",
    "        freq_itemsets: pd.DataFrame,\n",
    "        road_utilization: pd.DataFrame,\n",
    "        support_weight: float,\n",
    "        utilization_weight: float,\n",
    "        total_transactions:int\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Calculate critical routes with composite scores\"\"\"\n",
    "        analysis_df = freq_itemsets.copy()\n",
    "        \n",
    "        # Calculate support\n",
    "        # total_paths = max(analysis_df['freq'])\n",
    "        analysis_df['support'] = analysis_df['freq'] / total_transactions\n",
    "        \n",
    "        # Calculate utilization\n",
    "        analysis_df['avg_utilization'] = analysis_df['items'].apply(\n",
    "            lambda x: self.calculate_path_utilization(x, road_utilization)\n",
    "        )\n",
    "        \n",
    "        # Normalize utilization\n",
    "        min_util = analysis_df['avg_utilization'].min()\n",
    "        max_util = analysis_df['avg_utilization'].max()\n",
    "        analysis_df['normalized_utilization'] = (\n",
    "            (analysis_df['avg_utilization'] - min_util) / (max_util - min_util)\n",
    "            if max_util > min_util else 0\n",
    "        )\n",
    "        \n",
    "        # Calculate composite score\n",
    "        analysis_df['composite_score'] = (\n",
    "            support_weight * analysis_df['support'] +\n",
    "            utilization_weight * analysis_df['normalized_utilization']\n",
    "        )\n",
    "        \n",
    "        # Prepare result\n",
    "        result = (analysis_df\n",
    "                 .sort_values('composite_score', ascending=False)\n",
    "                 .reset_index(drop=True))\n",
    "        \n",
    "        # add column route_id\n",
    "        result['route_id'] = result.index + 1\n",
    "\n",
    "        # Round numerical columns\n",
    "        for col in ['support', 'avg_utilization', 'composite_score']:\n",
    "            result[col] = result[col].round(2)\n",
    "\n",
    "        # # Reorder columns to put route_id first\n",
    "        # all_cols = ['route_id'] + [col for col in result.columns if col != 'route_id']\n",
    "        # result = result[all_cols]\n",
    "        \n",
    "        return result[['route_id','items', 'freq', 'support', 'avg_utilization', 'composite_score']]\n",
    "\n",
    "class PathVisualizer:\n",
    "    \"\"\"Handles all visualization tasks\"\"\"\n",
    "    \n",
    "    def __init__(self, config: VisualizationConfig):\n",
    "        self.config = config\n",
    "        self.path_analyzer = PathAnalyzer()\n",
    "    \n",
    "\n",
    "    def visualize_critical_routes(self, critical_routes: pd.DataFrame, k_critical_path: int) -> plt.Figure:\n",
    "        \"\"\"Create main visualization for critical routes\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=self.config.fig_size)\n",
    "        \n",
    "        top_k_routes = critical_routes.nlargest(\n",
    "            k_critical_path, 'composite_score'\n",
    "        )\n",
    "\n",
    "        ax.bar(range(1, k_critical_path + 1), top_k_routes['composite_score'], \n",
    "            color='#66b3ff', edgecolor='black', width=0.7)\n",
    "\n",
    "        ax.set_xlabel('Top 20 most utilized paths', fontsize=self.config.text_size)\n",
    "        ax.set_ylabel('Composite Priority Score (CPS)', fontsize=self.config.text_size)\n",
    "        \n",
    "        ax.tick_params(axis='x', labelsize=self.config.text_size, rotation=45)\n",
    "        ax.tick_params(axis='y', labelsize=self.config.text_size)\n",
    "        \n",
    "        ax.grid(True, linestyle='--', alpha=0.6, axis='y', linewidth=0.7)\n",
    "\n",
    "        # Set integer ticks for x-axis\n",
    "        ax.set_xticks(range(1, k_critical_path + 1))\n",
    "        ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "        \n",
    "        # Keep y-axis as float\n",
    "        ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return fig\n",
    "    \n",
    "\n",
    "    def plot_length_distribution(self, critical_path_df: pd.DataFrame) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Plot path length distribution.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            DataFrame containing path data with 'path_length' column\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        plt.Figure\n",
    "            Figure object containing the visualization\n",
    "        \"\"\"\n",
    "        # Helper function to calculate path lengths\n",
    "        def get_path_length(items):\n",
    "            if isinstance(items, str):\n",
    "                try:\n",
    "                    items = eval(items)\n",
    "                except:\n",
    "                    return 1\n",
    "            return len(items) if isinstance(items, list) else 1\n",
    "        \n",
    "        # Calculate path lengths\n",
    "        analysis_df = critical_path_df.copy()\n",
    "        analysis_df['path_length'] = analysis_df['items'].apply(get_path_length)\n",
    "        \n",
    "        # # Add value labels\n",
    "        # for i, v in enumerate(length_dist):\n",
    "        #     ax.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "        # Create figure and axis\n",
    "        fig, ax = plt.subplots(figsize=self.config.fig_size)\n",
    "\n",
    "        # Calculate and plot length distribution\n",
    "        length_dist = analysis_df['path_length'].value_counts().sort_index()\n",
    "        length_dist.plot(kind='bar', ax=ax, color='#66b3ff', edgecolor='black', width=0.7)\n",
    "\n",
    "        # Customize plot\n",
    "        # ax.set_title('Distribution of Path Lengths', fontsize=self.config.text_size + 2, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel('Route length', fontsize=self.config.text_size, labelpad=15)\n",
    "        ax.set_ylabel('Frequency', fontsize=self.config.text_size, labelpad=15)\n",
    "\n",
    "        # Customize ticks and gridlines\n",
    "        ax.tick_params(axis='x', labelsize=self.config.text_size, rotation=45)\n",
    "        ax.tick_params(axis='y', labelsize=self.config.text_size)\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Add value labels on bars\n",
    "        # for i, v in enumerate(length_dist):\n",
    "        #     ax.text(i, v + 0.2, str(v), ha='center', va='bottom', fontsize=self.config.text_size-2)\n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def plot_specific_length_paths(self, df: pd.DataFrame, path_length: int, custome_fig_size: Tuple[int, int]) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Plot paths of specific length showing both frequency and composite score.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            DataFrame containing path data with 'path_length', 'freq', \n",
    "            'composite_score', and 'items' columns\n",
    "        path_length : int\n",
    "            Length of paths to visualize\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        plt.Figure\n",
    "            Figure object containing the visualization\n",
    "        \"\"\"\n",
    "        def get_path_length(items):\n",
    "            if isinstance(items, str):\n",
    "                try:\n",
    "                    items = eval(items)\n",
    "                except:\n",
    "                    return 1\n",
    "            return len(items) if isinstance(items, list) else 1\n",
    "            \n",
    "        analysis_df = df.copy()\n",
    "        analysis_df['path_length'] = analysis_df['items'].apply(get_path_length)\n",
    "        # custome_fig_size = (15, 15)\n",
    "        fig, ax1 = plt.subplots(figsize=custome_fig_size)\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        specific_paths = analysis_df[analysis_df['path_length'] == path_length].nlargest(\n",
    "            self.config.top_k, 'composite_score'\n",
    "        )\n",
    "        # Create x-axis labels combining route_id and items\n",
    "        x_labels = [f'{row[\"items\"]}' for _, row in specific_paths.iterrows()]\n",
    "        \n",
    "        if not specific_paths.empty:\n",
    "            x_space_pos = np.arange(len(x_labels))\n",
    "            width = 0.40\n",
    "            \n",
    "            bars1 = ax1.bar(x_space_pos - width/2, specific_paths['composite_score'],\n",
    "                        width, color='#66b3ff', label='Composite Priority Score (CPS)')\n",
    "            \n",
    "            bars2 = ax2.bar(x_space_pos + width/2, specific_paths['freq'],\n",
    "                        width, color='#ff6347', label='Frequency')\n",
    "            \n",
    "            ax1.set_xlabel('Route', fontsize=self.config.text_size)\n",
    "            ax1.set_ylabel('Composite Priority Score (CPS)', fontsize=self.config.text_size)\n",
    "            ax1.tick_params(axis='y', labelsize=self.config.text_size)\n",
    "            \n",
    "            ax2.set_ylabel('Frequency', fontsize=self.config.text_size)\n",
    "            ax2.tick_params(axis='y', labelsize=self.config.text_size)\n",
    "            \n",
    "            ax1.set_xticks(x_space_pos)\n",
    "            ax1.set_xticklabels(x_labels, rotation=90, ha='right', fontsize=self.config.text_size)\n",
    "            \n",
    "            ax1.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "            \n",
    "            lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            \n",
    "            # Place legend outside the plot at the top\n",
    "            fig.legend(lines1 + lines2, labels1 + labels2,\n",
    "                    loc='center', \n",
    "                    bbox_to_anchor=(0.5, .9),\n",
    "                    ncol=2,\n",
    "                    fontsize=self.config.text_size)\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, f'No paths of length {path_length} found',\n",
    "                    ha='center', va='center')\n",
    "        \n",
    "        # Adjust layout to make room for the legend\n",
    "        plt.subplots_adjust(top=0.85)\n",
    "        \n",
    "        # Save x_labels and composite_score in a csv file\n",
    "        output_df = pd.DataFrame({\n",
    "            'Path': x_labels,\n",
    "            'CPS': specific_paths['composite_score'].values\n",
    "        })\n",
    "        \n",
    "        \n",
    "        return fig, output_df\n",
    "\n",
    "    def plot_max_length_paths(self, df: pd.DataFrame) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Plot paths with maximum length showing multiple metrics and their details in a table.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            DataFrame containing path data with required columns: 'path_length', 'freq',\n",
    "            'items', 'composite_score', 'support', and 'avg_utilization'\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        plt.Figure\n",
    "            Figure object containing the visualization\n",
    "        \"\"\"\n",
    "        def get_path_length(items):\n",
    "            if isinstance(items, str):\n",
    "                try:\n",
    "                    items = eval(items)\n",
    "                except:\n",
    "                    return 1\n",
    "            return len(items) if isinstance(items, list) else 1\n",
    "        \n",
    "        # Calculate path lengths\n",
    "        analysis_df = df.copy()\n",
    "        analysis_df['path_length'] = analysis_df['items'].apply(get_path_length)\n",
    "        # analysis_df['route_id'] = range(1, len(analysis_df) + 1)\n",
    "\n",
    "        # Create figure and axes\n",
    "        fig, ax1 = plt.subplots(figsize=self.config.fig_size)\n",
    "        \n",
    "        # Create secondary axes\n",
    "        ax2 = ax1.twinx()  # for composite score\n",
    "        ax3 = ax1.twinx()  # for avg_utilization\n",
    "        \n",
    "        # Offset the right spines for visibility\n",
    "        ax3.spines['right'].set_position(('outward', 60))\n",
    "        \n",
    "        # Find and filter maximum length paths\n",
    "        max_length = analysis_df['path_length'].max()\n",
    "        max_paths = analysis_df[analysis_df['path_length'] == max_length].nlargest(\n",
    "            self.config.top_k, 'composite_score'\n",
    "        )\n",
    "        \n",
    "        if not max_paths.empty:\n",
    "            # Width for bars\n",
    "            width = 0.4  # Reduced width to accommodate four bars\n",
    "            \n",
    "           # composite_score on primary axis (left)\n",
    "            bars1 = ax1.bar(max_paths.index, max_paths['composite_score'],\n",
    "                        width, color='lightblue', label='Composite Score')\n",
    "            \n",
    "            bars2 = ax2.bar(max_paths.index - width, max_paths['freq'], \n",
    "                        width, color='lightgreen', label='Frequency')\n",
    "            \n",
    "            # Avg Utilization on third secondary axis\n",
    "            bars3 = ax3.bar(max_paths.index + width, max_paths['avg_utilization'], \n",
    "                        width, color='purple', label='Avg Utilization')\n",
    "            \n",
    "            # Customize axes  \n",
    "            # ax1.set_title(f'Top {self.config.top_k} Paths of Maximum Length ({max_length})')\n",
    "            ax1.set_xlabel('Route index', fontsize=self.config.text_size)\n",
    "            \n",
    "            ax1.set_ylabel('Composite Score', color='blue', fontsize=self.config.text_size)\n",
    "            ax2.set_ylabel('Frequency', color='green', fontsize=self.config.text_size) \n",
    "            ax3.set_ylabel('Avg. Utilization', color='purple', fontsize=self.config.text_size)\n",
    "            \n",
    "            ax1.tick_params(axis='y', labelcolor='blue', labelsize=self.config.text_size)\n",
    "            ax2.tick_params(axis='y', labelcolor='green', labelsize=self.config.text_size) \n",
    "            ax3.tick_params(axis='y', labelcolor='purple', labelsize=self.config.text_size)\n",
    "            \n",
    "            # Set x-ticks to route_ids\n",
    "            plt.xticks(max_paths.index, max_paths['route_id'], fontsize=self.config.text_size)\n",
    "            \n",
    "            # Add grid\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            # def autolabel(bars, ax):\n",
    "            #     for bar in bars:\n",
    "            #         height = bar.get_height()\n",
    "            #         ax.text(bar.get_x() + bar.get_width()/2, height,\n",
    "            #                f'{height:.2f}',\n",
    "            #                ha='center', va='bottom', rotation=45)\n",
    "            \n",
    "            # autolabel(bars1, ax1)\n",
    "            # autolabel(bars2, ax2)\n",
    "            # autolabel(bars3, ax3)\n",
    "            # autolabel(bars4, ax4)\n",
    "            \n",
    "            # Add legends\n",
    "            lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            lines3, labels3 = ax3.get_legend_handles_labels()\n",
    "            # lines4, labels4 = ax4.get_legend_handles_labels()\n",
    "            ax1.legend(lines1 + lines2 + lines3,\n",
    "                      labels1 + labels2 + labels3,\n",
    "                      loc='upper right',\n",
    "                      bbox_to_anchor=(1.4, 1))\n",
    "            \n",
    "            # Add details table\n",
    "            # self._add_path_details_table(max_paths, fig, ax1)\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, f'No paths of length {max_length} found',\n",
    "                    ha='center', va='center', fontsize=self.config.text_size-2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    \n",
    "    def _add_path_details_table(self, df: pd.DataFrame, fig: plt.Figure, ax: plt.Axes) -> None:\n",
    "        \"\"\"\n",
    "        Add a details table below the plot.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            DataFrame containing paths data\n",
    "        fig : plt.Figure\n",
    "            Figure object to add table to\n",
    "        ax : plt.Axes\n",
    "            Axes object of the plot\n",
    "        \"\"\"\n",
    "        # Prepare table data\n",
    "        table_data = [\n",
    "            [str(row['items']), \n",
    "             f\"{row['composite_score']:.3f}\"]  # Format score to 3 decimal places\n",
    "            for idx, row in df.iterrows()\n",
    "        ]\n",
    "        \n",
    "        if table_data:\n",
    "            # Create table\n",
    "            table = ax.table(\n",
    "                cellText=table_data,\n",
    "                colLabels=['Path', 'Composite Score'],\n",
    "                loc='bottom',\n",
    "                bbox=[0, -0.50, 1, 0.3]\n",
    "            )\n",
    "            \n",
    "            # Customize table appearance\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(self.config.text_size)\n",
    "            table.scale(1, 1.5)\n",
    "            \n",
    "            # Adjust cell wrapping for path column\n",
    "            for cell in table._cells:\n",
    "                if cell[1] == 1:  # Path column\n",
    "                    table._cells[cell].set_text_props(wrap=True)\n",
    "            \n",
    "            # Set column widths\n",
    "            table.auto_set_column_width([0, 1, 2])\n",
    "            \n",
    "            # Adjust subplot parameters to make room for table\n",
    "            plt.subplots_adjust(bottom=0.25)\n",
    "            \n",
    "            # Adjust layout while preserving space for table\n",
    "            plt.tight_layout(rect=[0, 0.25, 1, 1])\n",
    "\n",
    "class GraphDataLoader:\n",
    "    \"\"\"Handles loading and preprocessing of graph data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_road_history(output_dir: str, data_files: List[str]) -> pd.DataFrame:\n",
    "        # Create empty list to store dataframes\n",
    "        dfs = []\n",
    "        \n",
    "        # Load each file and append to list\n",
    "        for file_name in data_files:\n",
    "            try:\n",
    "                file_path = Path(output_dir) / file_name\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Select only required columns\n",
    "                columns = ['time', 'road_id', 'utilization', 'inv_utilization']\n",
    "                dfs.append(df[columns])\n",
    "                logger.info(f\"Successfully loaded {file_name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading {file_name}: {str(e)}\")\n",
    "                raise\n",
    "        \n",
    "        # Combine all dataframes\n",
    "        if dfs:\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "            logger.info(f\"Combined {len(dfs)} dataframes with {len(combined_df)} total rows\")\n",
    "            return combined_df\n",
    "        else:\n",
    "            raise ValueError(\"No data files were successfully loaded\")\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_road_utility(road_history, time_slot=48):\n",
    "        # Filter for the specific time slot\n",
    "        time_slot_data = road_history[\n",
    "            road_history['time'] == time_slot\n",
    "        ]\n",
    "\n",
    "        # Convert road_id to string and reset index\n",
    "        result_df = time_slot_data[['road_id','utilization']].copy()\n",
    "        result_df['road_id'] = result_df['road_id'].astype(str)\n",
    "        \n",
    "        return result_df.reset_index(drop=True)\n",
    "\n",
    "def main(config: VisualizationConfig):\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        # Initialize components\n",
    "        data_loader = GraphDataLoader()\n",
    "        path_analyzer = PathAnalyzer()\n",
    "        path_visualizer = PathVisualizer(config)\n",
    "        \n",
    "        # Get road history data\n",
    "        if not config.has_critical_path: \n",
    "            road_history = data_loader.load_road_history(\n",
    "                config.output_dir,\n",
    "                config.data_files\n",
    "            )\n",
    "        \n",
    "        for time_slot in config.time_slots:\n",
    "            logger.info(f\"\\nProcessing time slot: {time_slot}\")\n",
    "\n",
    "            # Get road utilization\n",
    "            if config.has_critical_path:\n",
    "                # save critical routes\n",
    "                critical_routes_path_file = Path(config.output_dir) / f'critical_routes/{config.day_type}/{config.day_type}_critical_routes_t{time_slot}.csv'\n",
    "                critical_routes =pd.read_csv(critical_routes_path_file)\n",
    "            else: \n",
    "                road_utilization_df = data_loader.get_road_utility(road_history, time_slot)\n",
    "\n",
    "                # Load frequent path data\n",
    "                ext = ''\n",
    "                if config.day_type == 'workday':\n",
    "                    if time_slot == 48:\n",
    "                        ext = '_sup0.0815'\n",
    "                    elif time_slot == 78:\n",
    "                        ext = '_sup0.085'\n",
    "                    elif time_slot == 108:\n",
    "                        ext = '_sup0.082'\n",
    "                \n",
    "                freq_path_file = f\"{config.frequent_path}{time_slot}{ext}.csv\"\n",
    "\n",
    "                freq_itemsets_df = pd.read_csv(freq_path_file)\n",
    "\n",
    "                transaction_stats={'workday':{48:224195, 78:228404, 108:224193},'holiday':{48:210230, 78:218566, 108:212580}} #node size 500\n",
    "                total_transactions = transaction_stats[config.day_type][time_slot]\n",
    "                \n",
    "                # Calculate critical routes\n",
    "                critical_routes = path_analyzer.calculate_critical_routes(\n",
    "                    freq_itemsets_df,\n",
    "                    road_utilization_df,\n",
    "                    config.support_weight,\n",
    "                    config.utilization_weight,\n",
    "                    total_transactions\n",
    "                )\n",
    "                \n",
    "                # save critical routes\n",
    "                os.makedirs(Path(config.output_dir) / f'critical_routes/{config.day_type}', exist_ok=True)\n",
    "                critical_routes_path_file = Path(config.output_dir) / f'critical_routes/{config.day_type}/{config.day_type}_critical_routes_t{time_slot}.csv'\n",
    "                critical_routes.to_csv(critical_routes_path_file, index=False)\n",
    "\n",
    "            # Create visualizations\n",
    "            # path distribution visualization\n",
    "            os.makedirs(Path(config.output_dir) / f'visualizations/{config.day_type}', exist_ok=True)\n",
    "            fig = path_visualizer.plot_length_distribution(critical_routes)\n",
    "            plt.savefig(\n",
    "                Path(config.output_dir) / f'visualizations/{config.day_type}/critical_paths_distribution_{config.day_type}_t{time_slot}.png',\n",
    "                bbox_inches='tight', dpi=300\n",
    "            )\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # length based path visualization\n",
    "            total_path_df = pd.DataFrame(columns=['Path', 'CPS', 'length'])\n",
    "    \n",
    "            for path_length in config.path_lengths_to_analyze:\n",
    "\n",
    "                custome_fig_size = (15, 18)\n",
    "                fig, path_df =path_visualizer.plot_specific_length_paths(\n",
    "                    critical_routes, path_length, custome_fig_size\n",
    "                )\n",
    "                plt.savefig(\n",
    "                    Path(config.output_dir) / f'visualizations/{config.day_type}/{config.day_type}_utilize_paths_len{path_length}_t{time_slot}.png',\n",
    "                    bbox_inches='tight', dpi=300\n",
    "                )\n",
    "                plt.close(fig)\n",
    "\n",
    "                # Add length column\n",
    "                path_df['length'] = path_length\n",
    "                total_path_df = pd.concat([total_path_df, path_df], ignore_index=True)\n",
    "\n",
    "            filename = Path(config.output_dir) / f'visualizations/{config.day_type}/{config.day_type}_utilize_paths_t{time_slot}.csv'\n",
    "            total_path_df.to_csv(filename, index=False)\n",
    "\n",
    "            # max path\n",
    "            # fig =path_visualizer.plot_max_length_paths(critical_routes)\n",
    "            # plt.savefig(\n",
    "            #     Path(config.output_dir) / f'visualizations/{config.day_type}/max_critical_paths_{config.day_type}_t{time_slot}.png',\n",
    "            #     bbox_inches='tight'\n",
    "            # )\n",
    "            # plt.close(fig)\n",
    "            \n",
    "            # Create composite score visualization\n",
    "            fig = path_visualizer.visualize_critical_routes(critical_routes, config.k_critical_path)\n",
    "            plt.savefig(\n",
    "                Path(config.output_dir) / f'visualizations/{config.day_type}/{config.day_type}_composite_scores_t{time_slot}.png',\n",
    "                bbox_inches='tight'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "            \n",
    "            logger.info(f\"Completed processing time slot {time_slot}\")\n",
    "        \n",
    "        logger.info(\"All visualizations completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    '''  data_files=[\n",
    "            'level1_road_history_workday_utilization_tune.csv',\n",
    "            'level2_road_history_workday_utilization_tune.csv'\n",
    "        ]\n",
    "        \n",
    "    '''\n",
    "    config = VisualizationConfig(\n",
    "        # output_dir=\"D:/Thesis/files_output_dir/output_utilization/\",\n",
    "        output_dir=\"C:/Users/mamun_pc/Dropbox/Thesis/data/output_data/output_utilization/tune_utilization/\",\n",
    "\n",
    "        ## workday-frequent_path\n",
    "        # data_files=[\n",
    "        #     'level1_road_history_workday_utilization_tune_AHP.csv',\n",
    "        #     'level2_road_history_workday_utilization_tune_AHP.csv'\n",
    "        # ],\n",
    "        # day_type = 'workday',\n",
    "        # # frequent_path = 'D:/Thesis/files_output_dir/output_utilization/frequent_paths/node_size_500/frequent_path_workday_t',\n",
    "        # frequent_path = 'C:/Users/mamun_pc/Dropbox/Thesis/data/output_data/output_utilization/tune_utilization/frequent_path/size_500/frequent_path_workday_t',\n",
    "\n",
    "        # ## holiday\n",
    "        data_files=[\n",
    "            'level1_road_history_holiday_utilization_tune_AHP.csv',\n",
    "            'level2_road_history_holiday_utilization_tune_AHP.csv'\n",
    "        ],\n",
    "        day_type = 'holiday',\n",
    "        frequent_path = 'C:/Users/mamun_pc/Dropbox/Thesis/data/output_data/output_utilization/tune_utilization/frequent_path/size_500/frequent_path_holiday_t',\n",
    "\n",
    "        time_slots=[108],  # 48, 78, 108\n",
    "        support_weight=0.7,\n",
    "        utilization_weight=0.3,\n",
    "        path_lengths_to_analyze=[8, 9, 10, 11, 12], #2, 3, 4, 5/ 8, 9,\n",
    "        k_critical_path =20,\n",
    "        has_critical_path = True,\n",
    "        top_k=10,\n",
    "        text_size = 28\n",
    "    )\n",
    "    \n",
    "    main(config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218566"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_stats={'workday':{48:224195, 78:228404, 108:224193},'holiday':{48:210230, 78:218566, 108:212580}}\n",
    "total_transactions = transaction_stats['holiday'][78]\n",
    "total_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route 1: 6252 (0.38), support: 0.16, avg_utilization: 0.38, composite_score: 0.41\n",
      "Route 2: 6252 (0.38), 6350 (0.36), support: 0.16, avg_utilization: 0.37, composite_score: 0.4\n",
      "Route 3: 6350 (0.36), support: 0.16, avg_utilization: 0.36, composite_score: 0.39\n",
      "Route 4: 5332 (0.34), support: 0.19, avg_utilization: 0.34, composite_score: 0.39\n",
      "Route 5: 6251 (0.33), 6252 (0.38), support: 0.16, avg_utilization: 0.35, composite_score: 0.39\n",
      "Route 6: 6251 (0.33), 6252 (0.38), 6350 (0.36), support: 0.16, avg_utilization: 0.35, composite_score: 0.38\n",
      "Route 7: 6252 (0.38), 6350 (0.36), 6351 (0.32), support: 0.16, avg_utilization: 0.35, composite_score: 0.38\n",
      "Route 8: 2396 (0.34), support: 0.17, avg_utilization: 0.34, composite_score: 0.38\n",
      "Route 9: 6252 (0.38), 6342 (0.33), support: 0.15, avg_utilization: 0.36, composite_score: 0.38\n",
      "Route 10: 2732 (0.34), support: 0.17, avg_utilization: 0.34, composite_score: 0.38\n",
      "Route 11: 6252 (0.38), 6342 (0.33), 6350 (0.36), support: 0.15, avg_utilization: 0.36, composite_score: 0.38\n",
      "Route 12: 6252 (0.38), 6351 (0.32), support: 0.16, avg_utilization: 0.35, composite_score: 0.38\n",
      "Route 13: 3698 (0.35), support: 0.15, avg_utilization: 0.35, composite_score: 0.38\n",
      "Route 14: 6251 (0.33), 6252 (0.38), 6350 (0.36), 6351 (0.32), support: 0.16, avg_utilization: 0.34, composite_score: 0.37\n",
      "Route 15: 2790 (0.35), support: 0.15, avg_utilization: 0.35, composite_score: 0.37\n",
      "Route 16: 2790 (0.35), 3698 (0.35), support: 0.15, avg_utilization: 0.35, composite_score: 0.37\n",
      "Route 17: 6251 (0.33), 6252 (0.38), 6342 (0.33), 6350 (0.36), support: 0.15, avg_utilization: 0.35, composite_score: 0.37\n",
      "Route 18: 6251 (0.33), 6350 (0.36), support: 0.16, avg_utilization: 0.34, composite_score: 0.37\n",
      "Route 19: 6251 (0.33), 6252 (0.38), 6351 (0.32), support: 0.16, avg_utilization: 0.34, composite_score: 0.37\n",
      "Route 20: 2458 (0.32), support: 0.19, avg_utilization: 0.32, composite_score: 0.37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_roads</th>\n",
       "      <th>route_utilizations</th>\n",
       "      <th>support</th>\n",
       "      <th>avg_utilization</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[6252]</td>\n",
       "      <td>[0.3776288707120788]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[6252, 6350]</td>\n",
       "      <td>[0.3776288707120788, 0.3554324353926731]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[6350]</td>\n",
       "      <td>[0.3554324353926731]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[5332]</td>\n",
       "      <td>[0.338703970788673]</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[6251, 6252]</td>\n",
       "      <td>[0.3264222680577252, 0.3776288707120788]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[6251, 6252, 6350]</td>\n",
       "      <td>[0.3264222680577252, 0.3776288707120788, 0.355...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[6252, 6350, 6351]</td>\n",
       "      <td>[0.3776288707120788, 0.3554324353926731, 0.316...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[2396]</td>\n",
       "      <td>[0.344626446650965]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[6252, 6342]</td>\n",
       "      <td>[0.3776288707120788, 0.3328964931110548]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[2732]</td>\n",
       "      <td>[0.3401711180889334]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[6252, 6342, 6350]</td>\n",
       "      <td>[0.3776288707120788, 0.3328964931110548, 0.355...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[6252, 6351]</td>\n",
       "      <td>[0.3776288707120788, 0.3169418740893571]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[3698]</td>\n",
       "      <td>[0.350006310267546]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[6251, 6252, 6350, 6351]</td>\n",
       "      <td>[0.3264222680577252, 0.3776288707120788, 0.355...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[2790]</td>\n",
       "      <td>[0.3470767833824489]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[2790, 3698]</td>\n",
       "      <td>[0.3470767833824489, 0.350006310267546]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[6251, 6252, 6342, 6350]</td>\n",
       "      <td>[0.3264222680577252, 0.3776288707120788, 0.332...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[6251, 6350]</td>\n",
       "      <td>[0.3264222680577252, 0.3554324353926731]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[6251, 6252, 6351]</td>\n",
       "      <td>[0.3264222680577252, 0.3776288707120788, 0.316...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[2458]</td>\n",
       "      <td>[0.3198559088008654]</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    route_id               route_roads  \\\n",
       "0          1                    [6252]   \n",
       "1          2              [6252, 6350]   \n",
       "2          3                    [6350]   \n",
       "3          4                    [5332]   \n",
       "4          5              [6251, 6252]   \n",
       "5          6        [6251, 6252, 6350]   \n",
       "6          7        [6252, 6350, 6351]   \n",
       "7          8                    [2396]   \n",
       "8          9              [6252, 6342]   \n",
       "9         10                    [2732]   \n",
       "10        11        [6252, 6342, 6350]   \n",
       "11        12              [6252, 6351]   \n",
       "12        13                    [3698]   \n",
       "13        14  [6251, 6252, 6350, 6351]   \n",
       "14        15                    [2790]   \n",
       "15        16              [2790, 3698]   \n",
       "16        17  [6251, 6252, 6342, 6350]   \n",
       "17        18              [6251, 6350]   \n",
       "18        19        [6251, 6252, 6351]   \n",
       "19        20                    [2458]   \n",
       "\n",
       "                                   route_utilizations  support  \\\n",
       "0                                [0.3776288707120788]     0.16   \n",
       "1            [0.3776288707120788, 0.3554324353926731]     0.16   \n",
       "2                                [0.3554324353926731]     0.16   \n",
       "3                                 [0.338703970788673]     0.19   \n",
       "4            [0.3264222680577252, 0.3776288707120788]     0.16   \n",
       "5   [0.3264222680577252, 0.3776288707120788, 0.355...     0.16   \n",
       "6   [0.3776288707120788, 0.3554324353926731, 0.316...     0.16   \n",
       "7                                 [0.344626446650965]     0.17   \n",
       "8            [0.3776288707120788, 0.3328964931110548]     0.15   \n",
       "9                                [0.3401711180889334]     0.17   \n",
       "10  [0.3776288707120788, 0.3328964931110548, 0.355...     0.15   \n",
       "11           [0.3776288707120788, 0.3169418740893571]     0.16   \n",
       "12                                [0.350006310267546]     0.15   \n",
       "13  [0.3264222680577252, 0.3776288707120788, 0.355...     0.16   \n",
       "14                               [0.3470767833824489]     0.15   \n",
       "15            [0.3470767833824489, 0.350006310267546]     0.15   \n",
       "16  [0.3264222680577252, 0.3776288707120788, 0.332...     0.15   \n",
       "17           [0.3264222680577252, 0.3554324353926731]     0.16   \n",
       "18  [0.3264222680577252, 0.3776288707120788, 0.316...     0.16   \n",
       "19                               [0.3198559088008654]     0.19   \n",
       "\n",
       "    avg_utilization  composite_score  \n",
       "0              0.38             0.41  \n",
       "1              0.37             0.40  \n",
       "2              0.36             0.39  \n",
       "3              0.34             0.39  \n",
       "4              0.35             0.39  \n",
       "5              0.35             0.38  \n",
       "6              0.35             0.38  \n",
       "7              0.34             0.38  \n",
       "8              0.36             0.38  \n",
       "9              0.34             0.38  \n",
       "10             0.36             0.38  \n",
       "11             0.35             0.38  \n",
       "12             0.35             0.38  \n",
       "13             0.34             0.37  \n",
       "14             0.35             0.37  \n",
       "15             0.35             0.37  \n",
       "16             0.35             0.37  \n",
       "17             0.34             0.37  \n",
       "18             0.34             0.37  \n",
       "19             0.32             0.37  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "time_slot = 108\n",
    "k_critical_path = 20\n",
    "\n",
    "## workday-frequent_path\n",
    "\n",
    "output_dir=\"C:/Users/mamun_pc/Dropbox/Thesis/data/output_data/output_utilization/tune_utilization/\"\n",
    "\n",
    "## workday-frequent_path\n",
    "# data_files=[\n",
    "#     'level1_road_history_workday_utilization_tune_AHP.csv',\n",
    "#     'level2_road_history_workday_utilization_tune_AHP.csv'\n",
    "# ]\n",
    "# day_type = 'workday'\n",
    "\n",
    "## holiday\n",
    "data_files=[\n",
    "        'level1_road_history_holiday_utilization_tune_AHP.csv',\n",
    "        'level2_road_history_holiday_utilization_tune_AHP.csv'\n",
    "    ]\n",
    "day_type = 'holiday'\n",
    "\n",
    "def get_road_utility(road_history, time_slot=48):\n",
    "    # Filter for the specific time slot\n",
    "    time_slot_data = road_history[road_history['time'] == time_slot]\n",
    "\n",
    "    # Convert road_id to string and reset index\n",
    "    result_df = time_slot_data[['road_id', 'utilization']].copy()\n",
    "    return result_df\n",
    "\n",
    "# Load each file and concatenate\n",
    "road_history_workday_utilization = pd.DataFrame()  # Initialize outside the loop\n",
    "for file_name in data_files:\n",
    "    file_path = Path(output_dir) / file_name  # Use Path for better path handling\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Select only required columns\n",
    "    columns = ['time', 'road_id', 'utilization', 'inv_utilization']\n",
    "    road_history_workday_utilization = pd.concat([road_history_workday_utilization, df[columns]], ignore_index=True) # Use concat\n",
    "\n",
    "critical_routes_path_file = Path(output_dir) / f'critical_routes/{day_type}/{day_type}_critical_routes_t{time_slot}.csv'\n",
    "critical_routes = pd.read_csv(critical_routes_path_file)\n",
    "\n",
    "top_k_routes = critical_routes.nlargest(k_critical_path, 'composite_score')\n",
    "\n",
    "road_utilization = get_road_utility(road_history_workday_utilization, time_slot=time_slot) # Use the time_slot variable\n",
    "\n",
    "route_details = []\n",
    "for _, row in top_k_routes.iterrows():\n",
    "    road_ids = eval(row[\"items\"]) # Be cautious using eval, consider ast.literal_eval for safer parsing\n",
    "    road_ids = [int(id) for id in road_ids]\n",
    "    route_utils = road_utilization[road_utilization['road_id'].isin(road_ids)]\n",
    "    # print(road_ids)\n",
    "    # Handle cases where no matching road_ids are found\n",
    "    if route_utils.empty:\n",
    "        print(f'Route {row[\"route_id\"]}: No utilization data found for this route.')\n",
    "        route_details.append({\n",
    "            'route_id': row['route_id'],\n",
    "            'route_roads': [],\n",
    "            'route_utilizations': []\n",
    "        })\n",
    "        continue  # Skip to the next route\n",
    "\n",
    "    # Create a formatted string with road IDs and their utilizations\n",
    "    route_util_str = ', '.join([f'{road_id} ({util:.2f})' for road_id, util in zip(route_utils['road_id'], route_utils['utilization'])])\n",
    "    print(f'Route {row[\"route_id\"]}: {route_util_str}, support: {row['support']}, avg_utilization: {row['avg_utilization']}, composite_score: {row['composite_score']}')\n",
    "\n",
    "    route_details.append({\n",
    "        'route_id': row['route_id'],\n",
    "        'route_roads': list(route_utils['road_id']),\n",
    "        'route_utilizations': list(route_utils['utilization']),\n",
    "        'support': row['support'], \n",
    "        'avg_utilization': row['avg_utilization'],\n",
    "        'composite_score': row['composite_score']\n",
    "    })\n",
    "\n",
    "route_details_df = pd.DataFrame(route_details)\n",
    "\n",
    "file_path = Path(output_dir) / f'visualizations/{day_type}/{day_type}_top_routes_t{time_slot}.csv'\n",
    "route_details_df.to_csv(file_path)\n",
    "route_details_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route 1: 6252 (0.55), support: 0.17, avg_utilization: 0.55, composite_score: 0.42\n",
      "Route 2: 6252 (0.55), 6350 (0.54), support: 0.17, avg_utilization: 0.54, composite_score: 0.41\n",
      "Route 3: 6350 (0.54), support: 0.17, avg_utilization: 0.54, composite_score: 0.41\n",
      "Route 4: 6251 (0.51), 6252 (0.55), 6350 (0.54), support: 0.17, avg_utilization: 0.53, composite_score: 0.4\n",
      "Route 5: 6251 (0.51), 6252 (0.55), support: 0.17, avg_utilization: 0.53, composite_score: 0.4\n",
      "Route 6: 5332 (0.52), support: 0.18, avg_utilization: 0.52, composite_score: 0.4\n",
      "Route 7: 6252 (0.55), 6350 (0.54), 6351 (0.50), support: 0.17, avg_utilization: 0.53, composite_score: 0.4\n",
      "Route 8: 6252 (0.55), 6342 (0.52), support: 0.16, avg_utilization: 0.54, composite_score: 0.4\n",
      "Route 9: 6252 (0.55), 6342 (0.52), 6350 (0.54), support: 0.16, avg_utilization: 0.54, composite_score: 0.4\n",
      "Route 10: 6252 (0.55), 6351 (0.50), support: 0.17, avg_utilization: 0.52, composite_score: 0.4\n",
      "Route 11: 2396 (0.53), support: 0.16, avg_utilization: 0.53, composite_score: 0.4\n",
      "Route 12: 6251 (0.51), 6252 (0.55), 6350 (0.54), 6351 (0.50), support: 0.17, avg_utilization: 0.52, composite_score: 0.4\n",
      "Route 13: 2790 (0.53), support: 0.16, avg_utilization: 0.53, composite_score: 0.4\n",
      "Route 14: 6251 (0.51), 6350 (0.54), support: 0.17, avg_utilization: 0.52, composite_score: 0.4\n",
      "Route 15: 2458 (0.50), support: 0.19, avg_utilization: 0.5, composite_score: 0.4\n",
      "Route 16: 2732 (0.51), support: 0.18, avg_utilization: 0.51, composite_score: 0.4\n",
      "Route 17: 3698 (0.53), support: 0.16, avg_utilization: 0.53, composite_score: 0.4\n",
      "Route 18: 6342 (0.52), 6350 (0.54), support: 0.16, avg_utilization: 0.53, composite_score: 0.39\n",
      "Route 19: 6251 (0.51), 6252 (0.55), 6351 (0.50), support: 0.17, avg_utilization: 0.52, composite_score: 0.39\n",
      "Route 20: 6251 (0.51), 6252 (0.55), 6342 (0.52), 6350 (0.54), support: 0.16, avg_utilization: 0.53, composite_score: 0.39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_roads</th>\n",
       "      <th>route_utilizations</th>\n",
       "      <th>support</th>\n",
       "      <th>avg_utilization</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[6252]</td>\n",
       "      <td>[0.5479440109655924]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[6252, 6350]</td>\n",
       "      <td>[0.5479440109655924, 0.5359416861619392]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[6350]</td>\n",
       "      <td>[0.5359416861619392]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[6251, 6252, 6350]</td>\n",
       "      <td>[0.509702947409311, 0.5479440109655924, 0.5359...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[6251, 6252]</td>\n",
       "      <td>[0.509702947409311, 0.5479440109655924]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[5332]</td>\n",
       "      <td>[0.5212053764979008]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[6252, 6350, 6351]</td>\n",
       "      <td>[0.5479440109655924, 0.5359416861619392, 0.500...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[6252, 6342]</td>\n",
       "      <td>[0.5479440109655924, 0.5224831896369657]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[6252, 6342, 6350]</td>\n",
       "      <td>[0.5479440109655924, 0.5224831896369657, 0.535...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[6252, 6351]</td>\n",
       "      <td>[0.5479440109655924, 0.5003549143928484]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[2396]</td>\n",
       "      <td>[0.5300583416249856]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[6251, 6252, 6350, 6351]</td>\n",
       "      <td>[0.509702947409311, 0.5479440109655924, 0.5359...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[2790]</td>\n",
       "      <td>[0.5306804793351256]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[6251, 6350]</td>\n",
       "      <td>[0.509702947409311, 0.5359416861619392]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[2458]</td>\n",
       "      <td>[0.5032758412424242]</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[2732]</td>\n",
       "      <td>[0.5138955422338929]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[3698]</td>\n",
       "      <td>[0.5312682228873578]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[6342, 6350]</td>\n",
       "      <td>[0.5224831896369657, 0.5359416861619392]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[6251, 6252, 6351]</td>\n",
       "      <td>[0.509702947409311, 0.5479440109655924, 0.5003...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[6251, 6252, 6342, 6350]</td>\n",
       "      <td>[0.509702947409311, 0.5479440109655924, 0.5224...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    route_id               route_roads  \\\n",
       "0          1                    [6252]   \n",
       "1          2              [6252, 6350]   \n",
       "2          3                    [6350]   \n",
       "3          4        [6251, 6252, 6350]   \n",
       "4          5              [6251, 6252]   \n",
       "5          6                    [5332]   \n",
       "6          7        [6252, 6350, 6351]   \n",
       "7          8              [6252, 6342]   \n",
       "8          9        [6252, 6342, 6350]   \n",
       "9         10              [6252, 6351]   \n",
       "10        11                    [2396]   \n",
       "11        12  [6251, 6252, 6350, 6351]   \n",
       "12        13                    [2790]   \n",
       "13        14              [6251, 6350]   \n",
       "14        15                    [2458]   \n",
       "15        16                    [2732]   \n",
       "16        17                    [3698]   \n",
       "17        18              [6342, 6350]   \n",
       "18        19        [6251, 6252, 6351]   \n",
       "19        20  [6251, 6252, 6342, 6350]   \n",
       "\n",
       "                                   route_utilizations  support  \\\n",
       "0                                [0.5479440109655924]     0.17   \n",
       "1            [0.5479440109655924, 0.5359416861619392]     0.17   \n",
       "2                                [0.5359416861619392]     0.17   \n",
       "3   [0.509702947409311, 0.5479440109655924, 0.5359...     0.17   \n",
       "4             [0.509702947409311, 0.5479440109655924]     0.17   \n",
       "5                                [0.5212053764979008]     0.18   \n",
       "6   [0.5479440109655924, 0.5359416861619392, 0.500...     0.17   \n",
       "7            [0.5479440109655924, 0.5224831896369657]     0.16   \n",
       "8   [0.5479440109655924, 0.5224831896369657, 0.535...     0.16   \n",
       "9            [0.5479440109655924, 0.5003549143928484]     0.17   \n",
       "10                               [0.5300583416249856]     0.16   \n",
       "11  [0.509702947409311, 0.5479440109655924, 0.5359...     0.17   \n",
       "12                               [0.5306804793351256]     0.16   \n",
       "13            [0.509702947409311, 0.5359416861619392]     0.17   \n",
       "14                               [0.5032758412424242]     0.19   \n",
       "15                               [0.5138955422338929]     0.18   \n",
       "16                               [0.5312682228873578]     0.16   \n",
       "17           [0.5224831896369657, 0.5359416861619392]     0.16   \n",
       "18  [0.509702947409311, 0.5479440109655924, 0.5003...     0.17   \n",
       "19  [0.509702947409311, 0.5479440109655924, 0.5224...     0.16   \n",
       "\n",
       "    avg_utilization  composite_score  \n",
       "0              0.55             0.42  \n",
       "1              0.54             0.41  \n",
       "2              0.54             0.41  \n",
       "3              0.53             0.40  \n",
       "4              0.53             0.40  \n",
       "5              0.52             0.40  \n",
       "6              0.53             0.40  \n",
       "7              0.54             0.40  \n",
       "8              0.54             0.40  \n",
       "9              0.52             0.40  \n",
       "10             0.53             0.40  \n",
       "11             0.52             0.40  \n",
       "12             0.53             0.40  \n",
       "13             0.52             0.40  \n",
       "14             0.50             0.40  \n",
       "15             0.51             0.40  \n",
       "16             0.53             0.40  \n",
       "17             0.53             0.39  \n",
       "18             0.52             0.39  \n",
       "19             0.53             0.39  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = \"D:/Thesis/files_output_dir/output_utilization/\"\n",
    "day_type = 'holiday'\n",
    "time_slot = 108\n",
    "k_critical_path = 20\n",
    "\n",
    "## workday-frequent_path\n",
    "data_files = [\n",
    "    'level1_road_history_holiday_utilization_tune.csv',\n",
    "    'level2_road_history_holiday_utilization_tune.csv'\n",
    "]\n",
    "\n",
    "def get_road_utility(road_history, time_slot=48):\n",
    "    # Filter for the specific time slot\n",
    "    time_slot_data = road_history[road_history['time'] == time_slot]\n",
    "\n",
    "    # Convert road_id to string and reset index\n",
    "    result_df = time_slot_data[['road_id', 'utilization']].copy()\n",
    "    return result_df\n",
    "\n",
    "# Load each file and concatenate\n",
    "road_history_utilization = pd.DataFrame()  # Initialize outside the loop\n",
    "for file_name in data_files:\n",
    "    file_path = Path(output_dir) / file_name  # Use Path for better path handling\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Select only required columns\n",
    "    columns = ['time', 'road_id', 'utilization', 'inv_utilization']\n",
    "    road_history_utilization = pd.concat([road_history_utilization, df[columns]], ignore_index=True) # Use concat\n",
    "\n",
    "critical_routes_path_file = Path(output_dir) / f'frequent_paths/{day_type}/{day_type}_critical_routes_t{time_slot}.csv'\n",
    "critical_routes = pd.read_csv(critical_routes_path_file)\n",
    "\n",
    "top_k_routes = critical_routes.nlargest(k_critical_path, 'composite_score')\n",
    "\n",
    "road_utilization = get_road_utility(road_history_utilization, time_slot=time_slot) # Use the time_slot variable\n",
    "\n",
    "route_details = []\n",
    "for _, row in top_k_routes.iterrows():\n",
    "    road_ids = eval(row[\"items\"]) # Be cautious using eval, consider ast.literal_eval for safer parsing\n",
    "    road_ids = [int(id) for id in road_ids]\n",
    "    route_utils = road_utilization[road_utilization['road_id'].isin(road_ids)]\n",
    "    # print(road_ids)\n",
    "    # Handle cases where no matching road_ids are found\n",
    "    if route_utils.empty:\n",
    "        print(f'Route {row[\"route_id\"]}: No utilization data found for this route.')\n",
    "        route_details.append({\n",
    "            'route_id': row['route_id'],\n",
    "            'route_roads': [],\n",
    "            'route_utilizations': []\n",
    "        })\n",
    "        continue  # Skip to the next route\n",
    "\n",
    "    # Create a formatted string with road IDs and their utilizations\n",
    "    route_util_str = ', '.join([f'{road_id} ({util:.2f})' for road_id, util in zip(route_utils['road_id'], route_utils['utilization'])])\n",
    "    print(f'Route {row[\"route_id\"]}: {route_util_str}, support: {row['support']}, avg_utilization: {row['avg_utilization']}, composite_score: {row['composite_score']}')\n",
    "\n",
    "    route_details.append({\n",
    "        'route_id': row['route_id'],\n",
    "        'route_roads': list(route_utils['road_id']),\n",
    "        'route_utilizations': list(route_utils['utilization']),\n",
    "        'support': row['support'], \n",
    "        'avg_utilization': row['avg_utilization'],\n",
    "        'composite_score': row['composite_score']\n",
    "    })\n",
    "\n",
    "route_details_df = pd.DataFrame(route_details)\n",
    "\n",
    "file_path = Path(output_dir) / f'visualizations/{day_type}/{day_type}_route_details_df_t{time_slot}.csv'\n",
    "route_details_df.to_csv(file_path)\n",
    "route_details_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12062']\n",
      "['12047']\n",
      "['12051', '12047']\n",
      "['12047', '13262']\n",
      "['12052', '12047']\n",
      "['12051', '12052', '12047']\n",
      "['12051']\n",
      "['12051', '12047', '13262']\n",
      "['12051', '12052', '12047', '13262']\n",
      "['12052', '12047', '13262']\n",
      "['12051', '12052']\n",
      "['12051', '13262']\n",
      "['12051', '12052', '13262']\n",
      "['12052']\n",
      "['13262']\n",
      "['12052', '13262']\n",
      "['12051', '12052', '12047', '13262', '12108']\n",
      "['12051', '12052', '12043', '12047', '13262']\n",
      "['12051', '12052', '12047', '12108']\n",
      "['12051', '12052', '12043', '12047']\n"
     ]
    }
   ],
   "source": [
    "for _, row in top_k_routes.iterrows():\n",
    "    road_ids = eval(row[\"items\"]) # Be cautious using eval, consider ast.literal_eval for safer parsing\n",
    "    road_ids = [int(id) for id in road_ids]\n",
    "    route_utils = road_utilization[road_utilization['road_id'].isin(road_ids)]\n",
    "    print(row[\"items\"])\n",
    "    # print(road_ids)\n",
    "    # print(route_utils)\n",
    "\n",
    "# print(road_utilization.head())\n",
    "# road_utilization[road_utilization['road_id']==130]['utilization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>items</th>\n",
       "      <th>freq</th>\n",
       "      <th>support</th>\n",
       "      <th>avg_utilization</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>path_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['12051', '12047']</td>\n",
       "      <td>24984</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['12047', '13262']</td>\n",
       "      <td>25460</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['12052', '12047']</td>\n",
       "      <td>24984</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>['12051', '12052']</td>\n",
       "      <td>24984</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>['12051', '13262']</td>\n",
       "      <td>24984</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    route_id               items   freq  support  avg_utilization  \\\n",
       "2          3  ['12051', '12047']  24984     0.11             0.69   \n",
       "3          4  ['12047', '13262']  25460     0.11             0.68   \n",
       "4          5  ['12052', '12047']  24984     0.11             0.68   \n",
       "10        11  ['12051', '12052']  24984     0.11             0.68   \n",
       "11        12  ['12051', '13262']  24984     0.11             0.68   \n",
       "\n",
       "    composite_score  path_length  \n",
       "2              0.35            2  \n",
       "3              0.35            2  \n",
       "4              0.35            2  \n",
       "10             0.34            2  \n",
       "11             0.34            2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_length=2\n",
    "top_k=10\n",
    "\n",
    "def get_path_length(items):\n",
    "            if isinstance(items, str):\n",
    "                try:\n",
    "                    items = eval(items)\n",
    "                except:\n",
    "                    return 1\n",
    "            return len(items) if isinstance(items, list) else 1\n",
    "            \n",
    "analysis_df = critical_routes.copy()\n",
    "analysis_df['path_length'] = analysis_df['items'].apply(get_path_length)\n",
    "\n",
    "# fig, ax1 = plt.subplots(figsize=self.config.fig_size)\n",
    "# ax2 = ax1.twinx()\n",
    "\n",
    "specific_paths = analysis_df[analysis_df['path_length'] == path_length].nlargest(\n",
    "    top_k, 'composite_score'\n",
    ")\n",
    "\n",
    "specific_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slot = 48\n",
    "# Load frequent path data\n",
    "freq_path_file = f\"{'D:/Thesis/files_output_dir/output_utilization/frequent_paths/frequent_path_holiday_t'}{time_slot}.csv\"\n",
    "\n",
    "freq_itemsets_df = pd.read_csv(freq_path_file)\n",
    "analysis_df = freq_itemsets_df.copy()\n",
    "        \n",
    "# # Calculate support\n",
    "# total_paths = analysis_df['freq'].sum()\n",
    "# analysis_df['support'] = analysis_df['freq'] / total_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              items   freq   support\n",
      "0                                          ['2565']  34847  0.015638\n",
      "1                                  ['2565', '2914']  31644  0.014201\n",
      "2                          ['2565', '2914', '3197']  31294  0.014044\n",
      "3                  ['2565', '2914', '3197', '2458']  29663  0.013312\n",
      "4                  ['2565', '2914', '3197', '2389']  31119  0.013965\n",
      "5          ['2565', '2914', '3197', '2389', '2458']  29663  0.013312\n",
      "6          ['2565', '2914', '3197', '2389', '4353']  31119  0.013965\n",
      "7  ['2565', '2914', '3197', '2389', '4353', '2458']  29663  0.013312\n",
      "8                  ['2565', '2914', '3197', '4353']  31294  0.014044\n",
      "9          ['2565', '2914', '3197', '4353', '2458']  29663  0.013312\n"
     ]
    }
   ],
   "source": [
    "# Calculate support\n",
    "# Assuming total transactions is the highest frequency (34847)\n",
    "total_transactions = len(analysis_df) #max(analysis_df['freq'])\n",
    "\n",
    "# Calculate support for each itemset\n",
    "analysis_df['support'] = analysis_df['freq'] / total_transactions\n",
    "\n",
    "# Display the result\n",
    "print(analysis_df[['items', 'freq', 'support']][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['2565']</td>\n",
       "      <td>34847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['2565', '2914']</td>\n",
       "      <td>31644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['2565', '2914', '3197']</td>\n",
       "      <td>31294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['2565', '2914', '3197', '2458']</td>\n",
       "      <td>29663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['2565', '2914', '3197', '2389']</td>\n",
       "      <td>31119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              items   freq\n",
       "0                          ['2565']  34847\n",
       "1                  ['2565', '2914']  31644\n",
       "2          ['2565', '2914', '3197']  31294\n",
       "3  ['2565', '2914', '3197', '2458']  29663\n",
       "4  ['2565', '2914', '3197', '2389']  31119"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42211"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(analysis_df['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2228319"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_transactions = len(analysis_df)\n",
    "total_transactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
